import re
import base64
import hashlib
import pefile
from datetime import datetime as dt
from pathlib import Path
from typing import Dict, List
from math import log2
from .patterns import (
    SUSPICIOUS_KEYWORDS,
    SUSPICIOUS_DOMAINS,
    SUSPICIOUS_FILENAMES,
    IP_REGEX,
    POWERSHELL_REGEX,
    REGISTRY_PATH_REGEX,
    YARA_RULE_REGEX,
    EICAR_SIGNATURE,
    HIGH_ENTROPY_THRESHOLD,
)

class MalwareAnalyzer:
    def extract_ascii_strings(self, binary_data, min_length=6):
        """Extract ASCII strings from binary data.
        The ASCII string will be matched against pattersn of printable characters using regular expressions."""
        pattern = rb"[\x20-\x7E]{%d,}" % min_length
        ascii_strings = re.findall(pattern, binary_data)
        return [s.decode("ascii", errors="ignore") for s in ascii_strings]

    def calculate_file_hashes(self, file_path: Path) -> Dict[str, str]:
        """Calculate multiple hash types for a file."""
        hashes = {'md5': hashlib.md5(), 'sha1': hashlib.sha1(), 'sha256': hashlib.sha256()}
        with open(file_path, 'rb') as file:
            while chunk := file.read(8192):
                for hasher in hashes.values():
                    hasher.update(chunk)
        return {name: hasher.hexdigest() for name, hasher in hashes.items()}

    def calculate_shannon_entropy(self, byte_sequence):
        """Calculate Shannon entropy for data.
        identify potentially malicious code by detecting obfuscation techniques like encryption or packing, 
        which tend to increase the randomness of the data. """
        if isinstance(byte_sequence, str):
            byte_sequence = byte_sequence.encode()
        if not byte_sequence:
            return 0.0
        frequency_table = [0] * 256
        for byte in byte_sequence:
            frequency_table[byte] += 1
        entropy = 0.0
        for byte_count in frequency_table:
            if byte_count:
                probability = byte_count / len(byte_sequence)
                entropy -= probability * log2(probability)
        return entropy

    def detect_pe_headers(self, file_path):
        """Extract PE header information.
        PE Headers only exist in exe files, therefore the .pyc file needs to be supplemented for an exe file"""
        if str(file_path).endswith('.pyc'):
            filename = Path(file_path).stem + '.exe'
            pe_file_path = Path(file_path).parent / filename
            print(f" Looking for PE executable: {pe_file_path}")
            if not pe_file_path.exists():
                print(f"PE executable not found: {pe_file_path}")
                return {
                    "entry_point": "N/A (.pyc file - no corresponding .exe found)",
                    "image_base": "N/A (.pyc file - no corresponding .exe found)",
                    "sections": [("N/A", "N/A", "N/A")],
                }
        else:
            pe_file_path = file_path
        try:
            pe = pefile.PE(str(pe_file_path))
            return {
                "entry_point": hex(getattr(pe.OPTIONAL_HEADER, "AddressOfEntryPoint", 0)),
                "image_base": hex(getattr(pe.OPTIONAL_HEADER, "ImageBase", 0)),
                "sections": [
                    (
                        section.Name.decode(errors="ignore").strip("\x00"),
                        hex(section.VirtualAddress),
                        hex(section.Misc_VirtualSize),
                    )
                    for section in pe.sections
                ],
            }
        except pefile.PEFormatError:
            return {
                "entry_point": "N/A (Not a valid PE file)",
                "image_base": "N/A (Not a valid PE file)",
                "sections": [("N/A", "N/A", "N/A")],
            }
        except FileNotFoundError:
            return {
                "entry_point": "N/A (File not found)",
                "image_base": "N/A (File not found)",
                "sections": [("N/A", "N/A", "N/A")],
            }
        except Exception as e:
            return {
                "entry_point": f"N/A (Error: {str(e)})",
                "image_base": f"N/A (Error: {str(e)})",
                "sections": [("N/A", "N/A", "N/A")],
            }

    def analyze_static_indicators(self, file_path: Path, binary_data: bytes, ascii_strings: List[str]) -> Dict:
        """Perform comprehensive static analysis."""
        results = {}
        file_stats = file_path.stat()
        results["file_info"] = {
            "File Name": file_path.name,
            "File Size": f"{file_stats.st_size:,} bytes",
            "Created": dt.fromtimestamp(file_stats.st_ctime).isoformat(),
            "Modified": dt.fromtimestamp(file_stats.st_mtime).isoformat(),
        }
        results["file_info"].update(self.calculate_file_hashes(file_path))
        results["pe_info"] = self.detect_pe_headers(file_path)
        results["suspicious_filenames"] = self.detect_suspicious_filenames(file_path, ascii_strings)
        results["suspicious_keywords"] = {
            "found": bool([kw for kw in SUSPICIOUS_KEYWORDS if any(kw.lower() in s.lower() for s in ascii_strings)]),
            "keywords_detected": [kw for kw in SUSPICIOUS_KEYWORDS if any(kw.lower() in s.lower() for s in ascii_strings)],
            "total_matches": len([kw for kw in SUSPICIOUS_KEYWORDS if any(kw.lower() in s.lower() for s in ascii_strings)])
        }
        results["suspicious_domains"] = self.detect_suspicious_domains(ascii_strings)
        ip_matches = list(set(re.findall(IP_REGEX, " ".join(ascii_strings))))
        results["ip_addresses"] = {
            "found": bool(ip_matches),
            "ip_addresses": ip_matches,
            "total_matches": len(ip_matches)
        }
        results["powershell_commands"] = {
            "found": bool([s for s in ascii_strings if re.search(POWERSHELL_REGEX, s, re.IGNORECASE)]),
            "powershell_commands": [s for s in ascii_strings if re.search(POWERSHELL_REGEX, s, re.IGNORECASE)],
            "total_matches": len([s for s in ascii_strings if re.search(POWERSHELL_REGEX, s, re.IGNORECASE)])
        }
        results["registry_paths"] = {
            "found": bool([s for s in ascii_strings if re.search(REGISTRY_PATH_REGEX, s)]),
            "registry_paths": [s for s in ascii_strings if re.search(REGISTRY_PATH_REGEX, s)],
            "total_matches": len([s for s in ascii_strings if re.search(REGISTRY_PATH_REGEX, s)])
        }
        results["yara_patterns"] = self.detect_yara_patterns(ascii_strings)
        results["base64_strings"] = self.detect_base64_data(ascii_strings)
        results["high_entropy_sections"] = []
        for offset in range(0, len(binary_data) - 256, 256):
            chunk = binary_data[offset:offset + 256]
            entropy = self.calculate_shannon_entropy(chunk)
            if entropy >= HIGH_ENTROPY_THRESHOLD:
                results["high_entropy_sections"].append((offset, entropy))
        results["eicar_detected"] = {
            "found": EICAR_SIGNATURE in binary_data,
            "signature_detected": EICAR_SIGNATURE in binary_data,
            "signature_info": "EICAR test signature detected!" if EICAR_SIGNATURE in binary_data else "No EICAR test signature detected"
        }
        return results

    def detect_suspicious_domains(self, ascii_strings):
        all_strings = ascii_strings
        found_domains = set()
        total_matches = 0
        all_text = " ".join(all_strings)
        for domain_pattern in SUSPICIOUS_DOMAINS:
            for string in all_strings:
                matches = re.findall(domain_pattern, string, re.IGNORECASE)
                for match in matches:
                    found_domains.add(f"{string[:50]}")
                    total_matches += 1
        url_pattern = r'https?://(?:www\.)?([a-zA-Z0-9\-\.]+\.[a-zA-Z]{2,})'
        urls = re.findall(url_pattern, all_text, re.IGNORECASE)
        for url_domain in urls:
            for domain_pattern in SUSPICIOUS_DOMAINS:
                if re.search(domain_pattern, url_domain, re.IGNORECASE):
                    found_domains.add(f"{url_domain}")
                    total_matches += 1
                    break
            suspicious_keywords = ['evil', 'malicious', 'fake', 'hacker', 'c2', 'backdoor', 'trojan', 'botnet']
            if any(keyword in url_domain.lower() for keyword in suspicious_keywords):
                found_domains.add(f"{url_domain}")
                total_matches += 1
        domain_pattern = r'\b([a-zA-Z0-9\-]+\.(?:com|net|org|info|biz|co|io|me|tk|ml|ga|cf))\b'
        domains = re.findall(domain_pattern, all_text, re.IGNORECASE)
        for domain in domains:
            for suspicious_pattern in SUSPICIOUS_DOMAINS:
                if re.search(suspicious_pattern, domain, re.IGNORECASE):
                    found_domains.add(f"Domain: {domain}")
                    total_matches += 1
                    break
            suspicious_keywords = ['evil', 'malicious', 'fake', 'hacker', 'c2', 'backdoor', 'trojan', 'botnet']
            if any(keyword in domain.lower() for keyword in suspicious_keywords):
                found_domains.add(f"{domain}")
                total_matches += 1
        return {
            "found": bool(found_domains),
            "domains_detected": sorted(list(found_domains)),
            "total_matches": total_matches
        }

    def detect_suspicious_filenames(self, file_path: Path, ascii_strings: List[str]):
        filename_matches = []
        embedded_matches = []
        for suspicious_name in SUSPICIOUS_FILENAMES:
            if suspicious_name.lower() in file_path.name.lower():
                filename_matches.append(suspicious_name)
            elif any(suspicious_name.lower() in string.lower() for string in ascii_strings):
                embedded_matches.append(suspicious_name)
        return {
            "found": bool(filename_matches or embedded_matches),
            "filename_matches": filename_matches,
            "embedded_matches": embedded_matches
        }

    def detect_yara_patterns(self, ascii_strings: List[str]):
        yara_patterns = [
            string for string in ascii_strings if re.search(YARA_RULE_REGEX, string)
        ]
        return {
            "found": bool(yara_patterns),
            "yara_patterns": yara_patterns,
            "total_matches": len(yara_patterns)
        }

    def detect_base64_data(self, ascii_strings: List[str], min_length=16):
        decoded_results = []
        for string_candidate in ascii_strings:
            if len(string_candidate) >= min_length and re.fullmatch(
                r"[A-Za-z0-9+/=]+", string_candidate
            ):
                try:
                    decoded_bytes = base64.b64decode(string_candidate, validate=True)
                    decoded_results.append((string_candidate, decoded_bytes[:32]))
                except Exception:
                    continue
        return {
            "found": bool(decoded_results),
            "base64_strings": decoded_results,
            "total_matches": len(decoded_results)
        }
